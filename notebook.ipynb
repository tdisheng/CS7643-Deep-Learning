{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "seed() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader, SubsetRandomSampler, Subset\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 14\u001b[0m torch\u001b[39m.\u001b[39;49mseed(\u001b[39m42\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: seed() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch # for models\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import pathlib\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,number_of_classes):\n",
    "        super().__init__() #Inheritance\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,padding=1,kernel_size=3)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=16)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,padding=1,kernel_size=3)\n",
    "        self.bn2=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu2=nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,padding=1,kernel_size=3)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=64)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.fc=nn.Linear(64*56*56, number_of_classes)\n",
    "\n",
    "    \n",
    "    def forward(self, Input):\n",
    "            \n",
    "        output=self.conv1(Input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output=self.pool1(output)\n",
    "        \n",
    "        output=self.conv2(output)\n",
    "        output=self.bn2(output)\n",
    "        output=self.relu2(output)\n",
    "        \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        output=self.pool3(output)\n",
    "        \n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "path = pathlib.Path(\"data/Rice_Image_Dataset\")\n",
    "dataset = datasets.ImageFolder(path, transform=preprocess)\n",
    "\n",
    "# dataset loader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Number of classes\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.7, 0.2, 0.1))\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Get the target values (labels) from the dataset\n",
    "targets = np.array(dataset.targets)\n",
    "\n",
    "val_prop = 0.2\n",
    "test_prop = 0.1\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_val_indices, test_indices, train_val_targets, test_targets = train_test_split(np.arange(len(dataset)), targets, test_size=test_prop, stratify=targets)\n",
    "\n",
    "# Split the train set into train and validation sets\n",
    "train_indices, val_indices, train_targets, val_targets = train_test_split(train_val_indices, train_val_targets, test_size=val_prop, stratify=train_val_targets)\n",
    "\n",
    "# Create custom PyTorch datasets for the train, validation, and test sets using the original dataset and the indices of the split data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create custom dataloaders for the train, validation, and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create custom dataloaders with batch_suize = 1 for the train, validation, and test sets\n",
    "train_dataloader_1 = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader_1 = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader_1 = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_shots(model, shots = 1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, lr=1e-3, momentum=0.9, num_classes=5):\n",
    "    # one/few shot learning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_in_features = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(model_in_features, num_classes).to(device)\n",
    "    optimizer = torch.optim.SGD([\n",
    "                        {'params': model.fc.parameters()}\n",
    "                    ],\n",
    "                    lr=lr,\n",
    "                    momentum=momentum\n",
    "                )\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for inputs, targets in train_dataloader:\n",
    "        counter += 1\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(predictions == targets.data)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if counter == shots:\n",
    "            break\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    train_acc /= len(train_dataloader.dataset)\n",
    "    val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "    print('Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "            .format(train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, device=device, lr=1e-3, momentum=0.9, num_classes=5, epochs=1):\n",
    "    # Freeze the weights of the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model_in_features = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(model_in_features, num_classes).to(device)\n",
    "    optimizer = torch.optim.SGD([\n",
    "                        {'params': model.fc.parameters()}\n",
    "                    ],\n",
    "                    lr=lr,\n",
    "                    momentum=momentum\n",
    "                )\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'running epoch {epoch+1}')\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(predictions == targets.data)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        train_acc /= len(train_dataloader.dataset)\n",
    "        val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "              .format(epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_specs(model):\n",
    "    total_params = 0 #default value\n",
    "    total_params = sum(\n",
    "        param.numel() for param in model.parameters()\n",
    "    )\n",
    "    return total_params\n",
    "\n",
    "def evaluate_model(model, train_dataloader, val_dataloader, test_dataloader, num_classes=5):\n",
    "    print('collecting param count')\n",
    "    total_params = get_model_specs(model)\n",
    "    print('collecting train accuracy')\n",
    "    train_acc, train_loss = get_acc(model=model, dataloader=train_dataloader, num_classes=num_classes)\n",
    "    print('collecting validation accuracy')\n",
    "    val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "    print('collecting test accuracy')\n",
    "    test_acc, test_loss = get_acc(model=model, dataloader=test_dataloader, num_classes=num_classes)\n",
    "    metrics_dict = {\n",
    "        'total_params': total_params,\n",
    "        'train_acc': train_acc,\n",
    "        'train_loss': train_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'test_loss': test_loss\n",
    "    }\n",
    "    metrics_idx = list(metrics_dict.keys())\n",
    "    metrics = pd.Series(data=metrics_dict, index=metrics_idx)\n",
    "    return metrics\n",
    "\n",
    "def get_acc(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            preds = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            # Store the predictions and targets\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            targets.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "    # Calculate the accuracy and average loss\n",
    "    accuracy = torchmetrics.functional.accuracy(torch.tensor(predictions), torch.tensor(targets), num_classes=num_classes, task='multiclass')\n",
    "    avg_loss = total_loss / total_samples\n",
    "    \n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "# model training\n",
    "not_pretrained_vgg_model_trained_one_shot = train_model_shots(not_pretrained_vgg_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_alexnet_model_trained_one_shot = train_model_shots(not_pretrained_alexnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_resnet_model_trained_one_shot = train_model_shots(not_pretrained_resnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_resnet_model_trained_one_shot = train_model_shots(pretrained_resnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_alexnet_model_trained_one_shot = train_model_shots(pretrained_alexnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_vgg_model_trained_one_shot = train_model_shots(pretrained_vgg_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "\n",
    "metrics_not_pretrained_vgg_model_one_shot = evaluate_model(not_pretrained_vgg_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_alexnet_model_one_shot = evaluate_model(not_pretrained_alexnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_resnet_model_one_shot = evaluate_model(not_pretrained_resnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_resnet_model_one_shot = evaluate_model(pretrained_resnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_alexnet_model_one_shot = evaluate_model(pretrained_alexnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_vgg_model_one_shot = evaluate_model(pretrained_vgg_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# print metrics\n",
    "print(\"Not pretrained VGG model trained one shot\")\n",
    "print(metrics_not_pretrained_vgg_model_one_shot)\n",
    "print(\"Not pretrained Alexnet model trained one shot\")\n",
    "print(metrics_not_pretrained_alexnet_model_one_shot)\n",
    "print(\"Not pretrained Resnet model trained one shot\")\n",
    "print(metrics_not_pretrained_resnet_model_one_shot)\n",
    "print(\"Pretrained Resnet model trained one shot\")\n",
    "print(metrics_pretrained_resnet_model_one_shot)\n",
    "print(\"Pretrained Alexnet model trained one shot\")\n",
    "print(metrics_pretrained_alexnet_model_one_shot)\n",
    "print(\"Pretrained VGG model trained one shot\")\n",
    "print(metrics_pretrained_vgg_model_one_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "# model training\n",
    "not_pretrained_vgg_model_trained_five_shots = train_model_shots(not_pretrained_vgg_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_alexnet_model_trained_five_shots = train_model_shots(not_pretrained_alexnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_resnet_model_trained_five_shots = train_model_shots(not_pretrained_resnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_resnet_model_trained_five_shots = train_model_shots(pretrained_resnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_alexnet_model_trained_five_shots = train_model_shots(pretrained_alexnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_vgg_model_trained_five_shots = train_model_shots(pretrained_vgg_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader_1, device=device, num_classes=NUM_CLASSES)\n",
    "\n",
    "metrics_not_pretrained_vgg_model_five_shots = evaluate_model(not_pretrained_vgg_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_alexnet_model_five_shots = evaluate_model(not_pretrained_alexnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_resnet_model_five_shots = evaluate_model(not_pretrained_resnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_resnet_model_five_shots = evaluate_model(pretrained_resnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_alexnet_model_five_shots = evaluate_model(pretrained_alexnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_vgg_model_five_shots = evaluate_model(pretrained_vgg_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# print metrics\n",
    "print(\"Not pretrained VGG model trained one shot\")\n",
    "print(metrics_not_pretrained_vgg_model_five_shots)\n",
    "print(\"Not pretrained Alexnet model trained one shot\")\n",
    "print(metrics_not_pretrained_alexnet_model_five_shots)\n",
    "print(\"Not pretrained Resnet model trained one shot\")\n",
    "print(metrics_not_pretrained_resnet_model_five_shots)\n",
    "print(\"Pretrained Resnet model trained one shot\")\n",
    "print(metrics_pretrained_resnet_model_five_shots)\n",
    "print(\"Pretrained Alexnet model trained one shot\")\n",
    "print(metrics_pretrained_alexnet_model_five_shots)\n",
    "print(\"Pretrained VGG model trained one shot\")\n",
    "print(metrics_pretrained_vgg_model_five_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "# model training\n",
    "not_pretrained_vgg_model_trained = train_model(not_pretrained_vgg_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "not_pretrained_alexnet_model_trained = train_model(not_pretrained_alexnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "not_pretrained_resnet_model_trained = train_model(not_pretrained_resnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_resnet_model_trained = train_model(pretrained_resnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_alexnet_model_trained = train_model(pretrained_alexnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_vgg_model_trained = train_model(pretrained_vgg_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "\n",
    "metrics_not_pretrained_vgg_model = evaluate_model(not_pretrained_vgg_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_alexnet_model = evaluate_model(not_pretrained_alexnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_resnet_model = evaluate_model(not_pretrained_resnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_resnet_model = evaluate_model(pretrained_resnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_alexnet_model = evaluate_model(pretrained_alexnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_vgg_model = evaluate_model(pretrained_vgg_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# print metrics\n",
    "print(\"Not pretrained VGG model trained one shot\")\n",
    "print(metrics_not_pretrained_vgg_model)\n",
    "print(\"Not pretrained Alexnet model trained one shot\")\n",
    "print(metrics_not_pretrained_alexnet_model)\n",
    "print(\"Not pretrained Resnet model trained one shot\")\n",
    "print(metrics_not_pretrained_resnet_model)\n",
    "print(\"Pretrained Resnet model trained one shot\")\n",
    "print(metrics_pretrained_resnet_model)\n",
    "print(\"Pretrained Alexnet model trained one shot\")\n",
    "print(metrics_pretrained_alexnet_model)\n",
    "print(\"Pretrained VGG model trained one shot\")\n",
    "print(metrics_pretrained_vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9634/497186507.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  accuracy = torchmetrics.functional.accuracy(torch.tensor(predictions), torch.tensor(targets), num_classes=num_classes, task='multiclass')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Train Loss: 1.7945, Train Acc: 0.9246, Val Loss: 0.9808, Val Acc: 0.2322\n",
      "running epoch 2\n",
      "Epoch [2/8], Train Loss: 0.1334, Train Acc: 0.9863, Val Loss: 0.9851, Val Acc: 0.1607\n",
      "running epoch 3\n",
      "Epoch [3/8], Train Loss: 0.0720, Train Acc: 0.9906, Val Loss: 0.9828, Val Acc: 0.1598\n",
      "running epoch 4\n",
      "Epoch [4/8], Train Loss: 0.0527, Train Acc: 0.9919, Val Loss: 0.9862, Val Acc: 0.1161\n",
      "running epoch 5\n",
      "Epoch [5/8], Train Loss: 0.0339, Train Acc: 0.9941, Val Loss: 0.9870, Val Acc: 0.1074\n",
      "running epoch 6\n",
      "Epoch [6/8], Train Loss: 0.0252, Train Acc: 0.9949, Val Loss: 0.9884, Val Acc: 0.0971\n",
      "running epoch 7\n",
      "Epoch [7/8], Train Loss: 0.0182, Train Acc: 0.9961, Val Loss: 0.9887, Val Acc: 0.1033\n",
      "running epoch 8\n",
      "Epoch [8/8], Train Loss: 0.0116, Train Acc: 0.9973, Val Loss: 0.9883, Val Acc: 0.0974\n",
      "collecting param count\n",
      "collecting train accuracy\n",
      "collecting validation accuracy\n",
      "collecting test accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_params           1027333\n",
       "train_acc       tensor(0.9984)\n",
       "train_loss            0.006872\n",
       "val_acc         tensor(0.9883)\n",
       "val_loss              0.097431\n",
       "test_acc        tensor(0.9903)\n",
       "test_loss             0.068937\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train CNN\n",
    "cnn_model = CNN(5).to(device)\n",
    "cnn_model_trained = train_model(cnn_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=8)\n",
    "metrics_cnn = evaluate_model(cnn_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

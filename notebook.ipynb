{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6546fc6fd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch # for models\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import pathlib\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,number_of_classes):\n",
    "        super().__init__() #Inheritance\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,padding=1,kernel_size=3)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=16)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.fc=nn.Linear(in_features=87616, out_features=number_of_classes)\n",
    "    \n",
    "    def forward(self, input):            \n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output=self.pool1(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "path = pathlib.Path(\"data/Rice_Image_Dataset\")\n",
    "dataset = datasets.ImageFolder(path, transform=preprocess)\n",
    "\n",
    "# dataset loader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Number of classes\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.7, 0.2, 0.1))\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Get the target values (labels) from the dataset\n",
    "targets = np.array(dataset.targets)\n",
    "\n",
    "val_prop = 0.2\n",
    "test_prop = 0.1\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_val_indices, test_indices, train_val_targets, test_targets = train_test_split(np.arange(len(dataset)), targets, test_size=test_prop, stratify=targets)\n",
    "\n",
    "# Split the train set into train and validation sets\n",
    "train_indices, val_indices, train_targets, val_targets = train_test_split(train_val_indices, train_val_targets, test_size=val_prop, stratify=train_val_targets)\n",
    "\n",
    "# Create custom PyTorch datasets for the train, validation, and test sets using the original dataset and the indices of the split data\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Create custom dataloaders for the train, validation, and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create custom dataloaders for one/few shot learning\n",
    "class OneShotDataset(Dataset):\n",
    "    def __init__(self, path, num_classes=5, transform=preprocess):\n",
    "        self.path = path\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        self.dataset = datasets.ImageFolder(root=path, transform=transform)\n",
    "        self.indices = self._get_one_shot_indices()\n",
    "        \n",
    "    def _get_one_shot_indices(self):\n",
    "        indices = [[] for _ in range(self.num_classes)]\n",
    "        for idx, (image, label) in enumerate(self.dataset):\n",
    "            indices[label].append(idx)\n",
    "        return indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_classes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch = []\n",
    "        labels = []\n",
    "        for class_idx in range(self.num_classes):\n",
    "            sample_idx = random.choice(self.indices[class_idx])\n",
    "            sample, label = self.dataset[sample_idx]\n",
    "            batch.append(sample)\n",
    "            labels.append(label)\n",
    "        batch = torch.stack(batch, dim=0)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return batch, labels\n",
    "\n",
    "one_shot_dataset = OneShotDataset(\"data/Rice_Image_Dataset/\")\n",
    "\n",
    "train_dataloader_1 = DataLoader(one_shot_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 has unique labels: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "batch, labels = next(iter(train_dataloader_1))\n",
    "print(f\"Batch 1 has unique labels: {labels.unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_shots(model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, lr=1e-3, momentum=0.9, num_classes=5, epochs=1):\n",
    "    # one/few shot learning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    if hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
    "        optimizer = torch.optim.SGD([\n",
    "            {'params': model.fc.parameters()}\n",
    "        ], lr=lr, momentum=momentum)\n",
    "    elif hasattr(model, 'classifier'):\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes).to(device)\n",
    "        optimizer = torch.optim.SGD([\n",
    "            {'params': model.classifier[-1].parameters()}\n",
    "        ], lr=lr, momentum=momentum)\n",
    "    else:\n",
    "        raise ValueError('Model has no fc or classifier attribute')\n",
    "        \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        counter = 0\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            targets = targets.squeeze(0)\n",
    "            inputs = inputs.squeeze(0)\n",
    "            counter += 1\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(predictions == targets.data)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if counter == shots:\n",
    "                break\n",
    "\n",
    "        train_loss /= 5\n",
    "        train_acc /= 5\n",
    "        val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "                .format(epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_dataloader=train_dataloader, val_dataloader=val_dataloader, device=device, lr=1e-3, momentum=0.9, num_classes=5, epochs=1):\n",
    "    # Freeze the weights of the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    try:\n",
    "        model_in_features = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(model_in_features, num_classes).to(device)\n",
    "        optimizer = torch.optim.SGD([\n",
    "                        {'params': model.fc.parameters()}\n",
    "                    ],\n",
    "                    lr=lr,\n",
    "                    momentum=momentum\n",
    "                )\n",
    "    except:\n",
    "        model_in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = torch.nn.Linear(model_in_features, num_classes).to(device)\n",
    "        optimizer = torch.optim.SGD([\n",
    "                            {'params': model.classifier[-1].parameters()}\n",
    "                        ],\n",
    "                        lr=lr,\n",
    "                        momentum=momentum\n",
    "                    )\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'running epoch {epoch+1}')\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(predictions == targets.data)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        train_acc /= len(train_dataloader.dataset)\n",
    "        val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "              .format(epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_specs(model):\n",
    "    total_params = 0 #default value\n",
    "    total_params = sum(\n",
    "        param.numel() for param in model.parameters()\n",
    "    )\n",
    "    return total_params\n",
    "\n",
    "def evaluate_model(model, train_dataloader, val_dataloader, test_dataloader, num_classes=5):\n",
    "    print('collecting param count')\n",
    "    total_params = get_model_specs(model)\n",
    "    print('collecting train accuracy')\n",
    "    train_acc, train_loss = get_acc(model=model, dataloader=train_dataloader, num_classes=num_classes)\n",
    "    print('collecting validation accuracy')\n",
    "    val_acc, val_loss = get_acc(model=model, dataloader=val_dataloader, num_classes=num_classes)\n",
    "    print('collecting test accuracy')\n",
    "    test_acc, test_loss = get_acc(model=model, dataloader=test_dataloader, num_classes=num_classes)\n",
    "    metrics_dict = {\n",
    "        'total_params': total_params,\n",
    "        'train_acc': train_acc,\n",
    "        'train_loss': train_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'test_loss': test_loss\n",
    "    }\n",
    "    metrics_idx = list(metrics_dict.keys())\n",
    "    metrics = pd.Series(data=metrics_dict, index=metrics_idx)\n",
    "    return metrics\n",
    "\n",
    "def get_acc(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            preds = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            # Store the predictions and targets\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "            targets.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "    # Calculate the accuracy and average loss\n",
    "    accuracy = torchmetrics.functional.accuracy(torch.tensor(predictions), torch.tensor(targets), num_classes=num_classes, task='multiclass')\n",
    "    avg_loss = total_loss / total_samples\n",
    "    \n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disheng/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/disheng/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/disheng/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/disheng/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/disheng/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training not pretrained resnet model\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_504/724179154.py:160: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  accuracy = torchmetrics.functional.accuracy(torch.tensor(predictions), torch.tensor(targets), num_classes=num_classes, task='multiclass')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.6168, Train Acc: 0.0000, Val Loss: 1.6092, Val Acc: 0.2674\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Epoch [2/10], Train Loss: 1.6094, Train Acc: 0.2000, Val Loss: 1.6092, Val Acc: 0.2714\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Epoch [3/10], Train Loss: 1.6060, Train Acc: 0.4000, Val Loss: 1.6091, Val Acc: 0.2750\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Epoch [4/10], Train Loss: 1.6078, Train Acc: 0.2000, Val Loss: 1.6091, Val Acc: 0.2764\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "Epoch [5/10], Train Loss: 1.6089, Train Acc: 0.2000, Val Loss: 1.6090, Val Acc: 0.2736\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "not_pretrained_cnn_model = CNN(5).to(device)\n",
    "\n",
    "# model training\n",
    "print('training not pretrained resnet model')\n",
    "not_pretrained_vgg_model_trained_one_shot = train_model_shots(not_pretrained_vgg_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training not pretrained alexnet model')\n",
    "not_pretrained_alexnet_model_trained_one_shot = train_model_shots(not_pretrained_alexnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training not pretrained resnet model')\n",
    "not_pretrained_resnet_model_trained_one_shot = train_model_shots(not_pretrained_resnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training pretrained resnet model')\n",
    "pretrained_resnet_model_trained_one_shot = train_model_shots(pretrained_resnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training pretrained alexnet model')\n",
    "pretrained_alexnet_model_trained_one_shot = train_model_shots(pretrained_alexnet_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training pretrained vgg model')\n",
    "pretrained_vgg_model_trained_one_shot = train_model_shots(pretrained_vgg_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "print('training not pretrained cnn model')\n",
    "not_pretrained_cnn_model_trained_one_shot = train_model_shots(not_pretrained_cnn_model, shots=1, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "\n",
    "# metrics_not_pretrained_vgg_model_one_shot = evaluate_model(not_pretrained_vgg_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_not_pretrained_alexnet_model_one_shot = evaluate_model(not_pretrained_alexnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_not_pretrained_resnet_model_one_shot = evaluate_model(not_pretrained_resnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_pretrained_resnet_model_one_shot = evaluate_model(pretrained_resnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_pretrained_alexnet_model_one_shot = evaluate_model(pretrained_alexnet_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_pretrained_vgg_model_one_shot = evaluate_model(pretrained_vgg_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "# metrics_not_pretrained_cnn_model_one_shot = evaluate_model(not_pretrained_cnn_model_trained_one_shot, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# # print metrics\n",
    "# print(\"Not pretrained VGG model trained one shot\")\n",
    "# print(metrics_not_pretrained_vgg_model_one_shot)\n",
    "# print(\"Not pretrained Alexnet model trained one shot\")\n",
    "# print(metrics_not_pretrained_alexnet_model_one_shot)\n",
    "# print(\"Not pretrained Resnet model trained one shot\")\n",
    "# print(metrics_not_pretrained_resnet_model_one_shot)\n",
    "# print(\"Pretrained Resnet model trained one shot\")\n",
    "# print(metrics_pretrained_resnet_model_one_shot)\n",
    "# print(\"Pretrained Alexnet model trained one shot\")\n",
    "# print(metrics_pretrained_alexnet_model_one_shot)\n",
    "# print(\"Pretrained VGG model trained one shot\")\n",
    "# print(metrics_pretrained_vgg_model_one_shot)\n",
    "# print(\"Not pretrained CNN model trained one shot\")\n",
    "# print(metrics_not_pretrained_cnn_model_one_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "# model training\n",
    "not_pretrained_vgg_model_trained_five_shots = train_model_shots(not_pretrained_vgg_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_alexnet_model_trained_five_shots = train_model_shots(not_pretrained_alexnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "not_pretrained_resnet_model_trained_five_shots = train_model_shots(not_pretrained_resnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_resnet_model_trained_five_shots = train_model_shots(pretrained_resnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_alexnet_model_trained_five_shots = train_model_shots(pretrained_alexnet_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "pretrained_vgg_model_trained_five_shots = train_model_shots(pretrained_vgg_model, shots=5, train_dataloader=train_dataloader_1, val_dataloader=val_dataloader, device=device, num_classes=NUM_CLASSES)\n",
    "\n",
    "metrics_not_pretrained_vgg_model_five_shots = evaluate_model(not_pretrained_vgg_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_alexnet_model_five_shots = evaluate_model(not_pretrained_alexnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_resnet_model_five_shots = evaluate_model(not_pretrained_resnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_resnet_model_five_shots = evaluate_model(pretrained_resnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_alexnet_model_five_shots = evaluate_model(pretrained_alexnet_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_vgg_model_five_shots = evaluate_model(pretrained_vgg_model_trained_five_shots, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# print metrics\n",
    "print(\"Not pretrained VGG model trained one shot\")\n",
    "print(metrics_not_pretrained_vgg_model_five_shots)\n",
    "print(\"Not pretrained Alexnet model trained one shot\")\n",
    "print(metrics_not_pretrained_alexnet_model_five_shots)\n",
    "print(\"Not pretrained Resnet model trained one shot\")\n",
    "print(metrics_not_pretrained_resnet_model_five_shots)\n",
    "print(\"Pretrained Resnet model trained one shot\")\n",
    "print(metrics_pretrained_resnet_model_five_shots)\n",
    "print(\"Pretrained Alexnet model trained one shot\")\n",
    "print(metrics_pretrained_alexnet_model_five_shots)\n",
    "print(\"Pretrained VGG model trained one shot\")\n",
    "print(metrics_pretrained_vgg_model_five_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "not_pretrained_resnet_model = torchvision.models.resnet34(pretrained=False).to(device)\n",
    "not_pretrained_alexnet_model = torchvision.models.alexnet(pretrained=False).to(device)\n",
    "not_pretrained_vgg_model = torchvision.models.vgg16(pretrained=False).to(device)\n",
    "pretrained_resnet_model = torchvision.models.resnet34(pretrained=True).to(device)\n",
    "pretrained_alexnet_model = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "pretrained_vgg_model = torchvision.models.vgg16(pretrained=True).to(device)\n",
    "not_pretrained_cnn_model = CNN(5).to(device)\n",
    "\n",
    "# model training\n",
    "not_pretrained_vgg_model_trained = train_model(not_pretrained_vgg_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "not_pretrained_alexnet_model_trained = train_model(not_pretrained_alexnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "not_pretrained_resnet_model_trained = train_model(not_pretrained_resnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_resnet_model_trained = train_model(pretrained_resnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_alexnet_model_trained = train_model(pretrained_alexnet_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "pretrained_vgg_model_trained = train_model(pretrained_vgg_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "not_pretrained_cnn_model_trained = train_model(not_pretrained_cnn_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=10)\n",
    "\n",
    "metrics_not_pretrained_vgg_model = evaluate_model(not_pretrained_vgg_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_alexnet_model = evaluate_model(not_pretrained_alexnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_resnet_model = evaluate_model(not_pretrained_resnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_resnet_model = evaluate_model(pretrained_resnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_alexnet_model = evaluate_model(pretrained_alexnet_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_pretrained_vgg_model = evaluate_model(pretrained_vgg_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_not_pretrained_cnn_model = evaluate_model(not_pretrained_cnn_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "\n",
    "# print metrics\n",
    "print(\"Not pretrained VGG model trained one shot\")\n",
    "print(metrics_not_pretrained_vgg_model)\n",
    "print(\"Not pretrained Alexnet model trained one shot\")\n",
    "print(metrics_not_pretrained_alexnet_model)\n",
    "print(\"Not pretrained Resnet model trained one shot\")\n",
    "print(metrics_not_pretrained_resnet_model)\n",
    "print(\"Pretrained Resnet model trained one shot\")\n",
    "print(metrics_pretrained_resnet_model)\n",
    "print(\"Pretrained Alexnet model trained one shot\")\n",
    "print(metrics_pretrained_alexnet_model)\n",
    "print(\"Pretrained VGG model trained one shot\")\n",
    "print(metrics_pretrained_vgg_model)\n",
    "print(\"Not pretrained CNN model trained one shot\")\n",
    "print(metrics_not_pretrained_cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9634/497186507.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  accuracy = torchmetrics.functional.accuracy(torch.tensor(predictions), torch.tensor(targets), num_classes=num_classes, task='multiclass')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], Train Loss: 1.7945, Train Acc: 0.9246, Val Loss: 0.9808, Val Acc: 0.2322\n",
      "running epoch 2\n",
      "Epoch [2/8], Train Loss: 0.1334, Train Acc: 0.9863, Val Loss: 0.9851, Val Acc: 0.1607\n",
      "running epoch 3\n",
      "Epoch [3/8], Train Loss: 0.0720, Train Acc: 0.9906, Val Loss: 0.9828, Val Acc: 0.1598\n",
      "running epoch 4\n",
      "Epoch [4/8], Train Loss: 0.0527, Train Acc: 0.9919, Val Loss: 0.9862, Val Acc: 0.1161\n",
      "running epoch 5\n",
      "Epoch [5/8], Train Loss: 0.0339, Train Acc: 0.9941, Val Loss: 0.9870, Val Acc: 0.1074\n",
      "running epoch 6\n",
      "Epoch [6/8], Train Loss: 0.0252, Train Acc: 0.9949, Val Loss: 0.9884, Val Acc: 0.0971\n",
      "running epoch 7\n",
      "Epoch [7/8], Train Loss: 0.0182, Train Acc: 0.9961, Val Loss: 0.9887, Val Acc: 0.1033\n",
      "running epoch 8\n",
      "Epoch [8/8], Train Loss: 0.0116, Train Acc: 0.9973, Val Loss: 0.9883, Val Acc: 0.0974\n",
      "collecting param count\n",
      "collecting train accuracy\n",
      "collecting validation accuracy\n",
      "collecting test accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_params           1027333\n",
       "train_acc       tensor(0.9984)\n",
       "train_loss            0.006872\n",
       "val_acc         tensor(0.9883)\n",
       "val_loss              0.097431\n",
       "test_acc        tensor(0.9903)\n",
       "test_loss             0.068937\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train CNN\n",
    "cnn_model = CNN(5).to(device)\n",
    "cnn_model_trained = train_model(cnn_model, train_dataloader=train_dataloader, device=device, num_classes=NUM_CLASSES, epochs=8)\n",
    "metrics_cnn = evaluate_model(cnn_model_trained, train_dataloader, val_dataloader, test_dataloader, 5)\n",
    "metrics_cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
